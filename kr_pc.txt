from collections import defaultdict
import math
from pprint import pprint

# -------------------------------
# âœ… Step 1: GIVEN CFG (rules only, no probabilities)
# -------------------------------
# These must match what could be used in the parse trees
base_grammar = {
    'S': [('NP', 'VP')],
    'VP': [('V', 'NP'), ('VP', 'PP')],
    'NP': [('NP', 'PP'), ('John',), ('Mary',), ('Denver',)],
    'PP': [('P', 'NP')],
    'V': [('called',)],
    'P': [('from',)],
}

# -------------------------------
# âœ… Step 2: GIVEN Parse Trees (from Slide 12)
# -------------------------------
tree1 = (
    'S',
    ('NP', ('John',)),
    ('VP',
        ('V', ('called',)),
        ('NP',
            ('NP', ('Mary',)),
            ('PP',
                ('P', ('from',)),
                ('NP', ('Denver',))
            )
        )
    )
)

tree2 = (
    'S',
    ('NP', ('John',)),
    ('VP',
        ('VP',
            ('V', ('called',)),
            ('NP', ('Mary',))
        ),
        ('PP',
            ('P', ('from',)),
            ('NP', ('Denver',))
        )
    )
)

# -------------------------------
# âœ… Step 3: Extract rule counts
# -------------------------------
def extract_rules(tree, rule_counts):
    if isinstance(tree, tuple) and len(tree) >= 2:
        lhs = tree[0]
        rhs = tuple(child[0] if isinstance(child, tuple) else child for child in tree[1:])
        rule_counts[lhs][rhs] += 1
        for child in tree[1:]:
            extract_rules(child, rule_counts)

rule_counts = defaultdict(lambda: defaultdict(int))
for tree in [tree1, tree2]:
    extract_rules(tree, rule_counts)

# -------------------------------
# âœ… Step 4: Compute Probabilities and attach to base grammar
# -------------------------------
def build_probabilistic_grammar(base_rules, rule_counts):
    pcfg = defaultdict(dict)
    for lhs, rhss in base_rules.items():
        total_lhs_count = sum(rule_counts[lhs].values())
        for rhs in rhss:
            count = rule_counts[lhs][tuple(rhs)]
            prob = count / total_lhs_count if total_lhs_count > 0 else 0.0
            pcfg[lhs][tuple(rhs)] = prob
    return pcfg

grammar_probs = build_probabilistic_grammar(base_grammar, rule_counts)

print("ðŸ“˜ Grammar with Probabilities (Learned from Trees):")
pprint(dict(grammar_probs))

# -------------------------------
# âœ… Step 5: Run Probabilistic CYK
# -------------------------------
def pcyk(words, grammar, start_symbol='S'):
    n = len(words)
    table = [[defaultdict(lambda: (-math.inf, None)) for _ in range(n)] for _ in range(n)]

    for i, word in enumerate(words):
        for lhs in grammar:
            for rhs, prob in grammar[lhs].items():
                if len(rhs) == 1 and rhs[0] == word and prob > 0:
                    table[i][i][lhs] = (math.log(prob), word)

    for span in range(2, n + 1):
        for i in range(n - span + 1):
            j = i + span - 1
            for k in range(i, j):
                for lhs in grammar:
                    for rhs, prob in grammar[lhs].items():
                        if len(rhs) == 2 and prob > 0:
                            B, C = rhs
                            if B in table[i][k] and C in table[k + 1][j]:
                                prob_B, left_tree = table[i][k][B]
                                prob_C, right_tree = table[k + 1][j][C]
                                total_prob = prob_B + prob_C + math.log(prob)
                                if total_prob > table[i][j][lhs][0]:
                                    table[i][j][lhs] = (total_prob, (lhs, left_tree, right_tree))

    return table[0][n - 1][start_symbol][1] if start_symbol in table[0][n - 1] else None

# -------------------------------
# âœ… Step 6: Parse sentence
# -------------------------------
sentence = ["John", "called", "Mary", "from", "Denver"]
parse_tree = pcyk(sentence, grammar_probs)

print("\nðŸŒ³ Most Probable Parse Tree:")
pprint(parse_tree)
